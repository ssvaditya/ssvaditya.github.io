---
title: "MemEye"
excerpt: "Learning phase classification using biosignals and pupil data  <br/><img src='/images/memeye.jpg'>"
collection: portfolio
---
### Overview
Memeye is a real-time bio-signal processing system that accurately identifies human learning phases by combining pupil dilation data and electrodermal activity. The system processes multiple bio-signals from pupil labs and emotibit simultaneously to understand a learner's cognitive state, enabling adaptive learning systems to automatically adjust content difficulty.

### Role & Contributions
- Led the development of an end-to-end inference pipeline for real-time bio-signal processing
- Designed and implemented signal processing algorithms for noise reduction and feature extraction
- Created a multi-modal fusion architecture to combine insights from pupil data and electrodermal activity
- Built an efficient real-time processing system that runs on standard hardware

### Key Findings
- Achieved 98% accuracy in learning phase classification through multi-modal bio-signal analysis
- Demonstrated that combining pupil dilation and electrodermal activity provides more reliable classification than single-source data
- Established that real-time processing of bio-signals is feasible for practical applications
- Validated the system's ability to detect subtle changes in cognitive states during learning

### Impact & Implications
- Currently preparing two papers from this research:
    - A dataset paper documenting the collection and analysis of multi-modal bio-signal data during learning
    - An experimental paper focusing on the system's methodology and classification results
- Opens new possibilities for personalized learning experiences based on cognitive state
- Provides a foundation for developing more sophisticated human-AI interaction systems
- Demonstrates the potential of multi-modal bio-signal processing for understanding human cognitive states

To know more about this work:
[Code](https://github.com/MemEye/memeye_studies)

